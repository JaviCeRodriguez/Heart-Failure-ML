{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classification es el notebook oficial de clasificación\n",
    "\n",
    "### - Limpiamos los datos según conclusiones del notebook main\n",
    "### - Probaremos distintos algorítmos de clasificación y compararemos los resultados\n",
    "### - Utilizamos el dataset de train ya recortado por la cátedra (igual creamos un test para pruebas internas)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACA TODOS LOS IMPORTS DEL NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict, StratifiedShuffleSplit\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import recall_score, confusion_matrix, ConfusionMatrixDisplay, precision_recall_curve, auc, roc_auc_score, roc_curve, RocCurveDisplay, PrecisionRecallDisplay, plot_precision_recall_curve, plot_roc_curve "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LECTURA Y LIMPIEZA DEL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv(r\"DS_G3_HeartFailure_FULL_train.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_orig.copy()\n",
    "feat_train, feat_test, targ_train, targ_test = train_test_split(df_cleaned.drop([\"DEATH_EVENT\"],axis=1),df_cleaned[\"DEATH_EVENT\"],test_size=0.2,random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n"
     ]
    }
   ],
   "source": [
    "rfe = RFECV(RandomForestClassifier(n_estimators=2000),scoring=\"recall\",min_features_to_select=5,cv=10,verbose=1,n_jobs=-1)\n",
    "rfe = rfe.fit(feat_train,targ_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('age', True)\n",
      "('anaemia', False)\n",
      "('creatinine_phosphokinase', True)\n",
      "('diabetes', False)\n",
      "('ejection_fraction', True)\n",
      "('high_blood_pressure', False)\n",
      "('platelets', True)\n",
      "('serum_creatinine', True)\n",
      "('serum_sodium', True)\n",
      "('sex', False)\n",
      "('smoking', False)\n",
      "('time', True)\n"
     ]
    }
   ],
   "source": [
    "for feat in zip(feat_train.columns,rfe.support_):\n",
    "    print(feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones necesarias al df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_orig[\"cant_path\"] = df_orig[\"anaemia\"]+df_orig[\"high_blood_pressure\"]+df_orig[\"diabetes\"]\n",
    "#df_cleaned = df_orig.copy()\n",
    "df_cleaned = df_orig.drop([\"time\",\"anaemia\",\"diabetes\",\"high_blood_pressure\",\"sex\",\"smoking\"],axis=1)\n",
    "#df_cleaned = df_orig.drop([\"anaemia\",\"diabetes\",\"high_blood_pressure\",\"sex\",\"smoking\"],axis=1)\n",
    "# NOS QUEDAMOS CON AGE, EJECTION_FRACTION, SERUM_CREATININE, SERUM_SODIUM Y DEATH_EVENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>95.0</td>\n",
       "      <td>371</td>\n",
       "      <td>30</td>\n",
       "      <td>461000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>40.0</td>\n",
       "      <td>478</td>\n",
       "      <td>30</td>\n",
       "      <td>303000.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>70.0</td>\n",
       "      <td>232</td>\n",
       "      <td>30</td>\n",
       "      <td>173000.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>70.0</td>\n",
       "      <td>2695</td>\n",
       "      <td>40</td>\n",
       "      <td>241000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>59.0</td>\n",
       "      <td>176</td>\n",
       "      <td>25</td>\n",
       "      <td>221000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  creatinine_phosphokinase  ejection_fraction  platelets  \\\n",
       "55   95.0                       371                 30   461000.0   \n",
       "180  40.0                       478                 30   303000.0   \n",
       "237  70.0                       232                 30   173000.0   \n",
       "280  70.0                      2695                 40   241000.0   \n",
       "181  59.0                       176                 25   221000.0   \n",
       "\n",
       "     serum_creatinine  serum_sodium  DEATH_EVENT  \n",
       "55                2.0           132            1  \n",
       "180               0.9           136            0  \n",
       "237               1.2           132            0  \n",
       "280               1.0           137            0  \n",
       "181               1.0           136            1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_train, feat_test, targ_train, targ_test = train_test_split(df_cleaned.drop([\"DEATH_EVENT\"],axis=1),df_cleaned[\"DEATH_EVENT\"],test_size=0.2,random_state=69)\n",
    "#HAY QUE SEPARAR EL TEST ANTES DE ESTANDARIZAR PARA QUE NO INFLUYAN LOS FEATURES DE TEST EN LA MEDIA Y VARIANZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "feat_train = scaler.fit_transform(feat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APLICAMOS SMOTE PARA AUMENTAR LA CANTIDAD DE SAMPLES Y BALANCEAR EL TARGET\n",
    "feat_train, targ_train = SMOTE().fit_resample(feat_train, targ_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACA TENEMOS EL DATASET RECORTADO Y STANDARIZADO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sss = StratifiedShuffleSplit() # USAMOS ESTO PARA CV POR EL DESBALANCE (si usamos smote no hay desbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_metric = \"recall\" # Queremos pocos FN, es decir pacientes q decimos q NO tienen riesgo pero SI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La teoría indica que el Logistic Regressor no tiene hyperparametros q valgan la pena tunear mas allá del penalty o un poco el \"C\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'poly__degree': 2, 'regressor__C': 1.8047217668271664e-18}\n",
      "Grilla Best Score: 0.896\n",
      "Cross Validation Score: 0.896 +/- 0.059\n"
     ]
    }
   ],
   "source": [
    "hyperparam = {\"poly__degree\":[n for n in range(1,5)],\"regressor__C\":[n for n in np.logspace(-20,2, num=40)]}\n",
    "lr_model = Pipeline([[\"poly\",PolynomialFeatures()],[\"regressor\",LogisticRegression(fit_intercept=False, max_iter=20000)]])\n",
    "lr_grilla = GridSearchCV(lr_model,hyperparam,cv=10,scoring=score_metric,n_jobs=-1)\n",
    "lr_grilla.fit(feat_train,targ_train)\n",
    "lr_model = lr_grilla.best_estimator_\n",
    "print(lr_grilla.best_params_)\n",
    "print(\"Grilla Best Score: {:.3f}\".format(lr_grilla.best_score_))\n",
    "lr_scoring = cross_val_score(lr_model, feat_train, targ_train,cv=10, scoring=score_metric)\n",
    "print(\"Cross Validation Score: {:.3f} +/- {:.3f}\".format(lr_scoring.mean(),lr_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring en Test: 0.474\n"
     ]
    }
   ],
   "source": [
    "#print(\"Scoring en Test: {:.3f}\".format(recall_score(targ_test,lr_model.predict)((feat_test-t_mean)/t_var)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SVC__C': 8.254041852680206e-18, 'poly__degree': 2}\n",
      "Grilla Best Score: 0.896\n",
      "Cross Validation Score: 0.896 +/- 0.059\n"
     ]
    }
   ],
   "source": [
    "hyperparam = {\"poly__degree\":[n for n in range(1,4)],\"SVC__C\":[n for n in np.logspace(-20,-10, num=25)]}\n",
    "svml_model = Pipeline([[\"poly\",PolynomialFeatures()],[\"SVC\",LinearSVC(fit_intercept=False, max_iter=30000,dual=False)]])\n",
    "svml_grilla = GridSearchCV(svml_model,hyperparam,cv=10,scoring=score_metric,n_jobs=-1)\n",
    "svml_grilla.fit(feat_train,targ_train)\n",
    "print(svml_grilla.best_params_)\n",
    "svml_model = svml_grilla.best_estimator_\n",
    "print(\"Grilla Best Score: {:.3f}\".format(svml_grilla.best_score_))\n",
    "svml_scoring = cross_val_score(svml_model, feat_train, targ_train,cv=10, scoring=score_metric)\n",
    "print(\"Cross Validation Score: {:.3f} +/- {:.3f}\".format(svml_scoring.mean(),svml_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring en Test: 0.632\n"
     ]
    }
   ],
   "source": [
    "#print(\"Scoring en Test: {:.3f}\".format(recall_score(targ_test,svml_model.predict((feat_test-t_mean)/t_var))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM no lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10.0, 'gamma': 0.3831186849557287, 'kernel': 'rbf'}\n",
      "Grilla Best Score: 0.884\n",
      "Cross Validation Score: 0.884 +/- 0.153\n"
     ]
    }
   ],
   "source": [
    "hyperparam = {\"kernel\":[\"rbf\",\"poly\",\"sigmoid\"],\"C\":[n for n in np.logspace(-1,2, num=10)],\"gamma\":[n for n in np.logspace(-2,0, num=10)]}\n",
    "svm_model = SVC()\n",
    "svm_grilla = GridSearchCV(svm_model,hyperparam,cv=10,scoring=score_metric,n_jobs=-1)\n",
    "svm_grilla.fit(feat_train,targ_train)\n",
    "print(svm_grilla.best_params_)\n",
    "svm_model = svm_grilla.best_estimator_\n",
    "print(\"Grilla Best Score: {:.3f}\".format(svm_grilla.best_score_))\n",
    "svm_scoring = cross_val_score(svm_model, feat_train, targ_train,cv=10, scoring=score_metric)\n",
    "print(\"Cross Validation Score: {:.3f} +/- {:.3f}\".format(svm_scoring.mean(),svm_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring en Test: 0.895\n"
     ]
    }
   ],
   "source": [
    "#print(\"Scoring en Test: {:.3f}\".format(recall_score(targ_test,svm_model.predict((feat_test-t_mean)/t_var))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_depth: por defecto es None, controla la profundidad del arbol.\n",
    "min_samples_split: establece el minimo numero de muestras que debe tener un nodo para poder seguir partiendolo.\n",
    "min_samples_leaf: el minimo numero de muestras que debe tener una hoja (ie nodo final).\n",
    "min_weight_fraction_leaf: la minima fraccion pesada de muestras que debe poseer una hoja.\n",
    "max_leaf_nodes: maxima cantidad de hojas.\n",
    "max_features: maxima cantidad de features evaluados en un splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_leaf_nodes': 500}\n",
      "Grilla Best Score: 0.763\n",
      "Cross Validation Score: 0.755 +/- 0.133\n"
     ]
    }
   ],
   "source": [
    "hyperparam = {\"max_depth\":[n for n in range(1,7)],\"max_leaf_nodes\":[2,10,50,500,1000]}\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_grilla = GridSearchCV(dt_model,hyperparam,cv=10,scoring=score_metric,n_jobs=-1)\n",
    "dt_grilla.fit(feat_train,targ_train)\n",
    "print(dt_grilla.best_params_)\n",
    "dt_model = dt_grilla.best_estimator_\n",
    "print(\"Grilla Best Score: {:.3f}\".format(dt_grilla.best_score_))\n",
    "dt_scoring = cross_val_score(dt_model, feat_train, targ_train,cv=10, scoring=score_metric)\n",
    "print(\"Cross Validation Score: {:.3f} +/- {:.3f}\".format(dt_scoring.mean(),dt_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring en Test: 0.316\n"
     ]
    }
   ],
   "source": [
    "#print(\"Scoring en Test: {:.3f}\".format(recall_score(targ_test,dt_model.predict((feat_test-t_mean)/t_var))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 8, 'min_samples_leaf': 2, 'n_estimators': 500}\n",
      "Grilla Best Score: 0.816\n",
      "Cross Validation Score: 0.809 +/- 0.163\n"
     ]
    }
   ],
   "source": [
    "hyperparam = {\"n_estimators\":[500,1000,2000],\"max_depth\":[n for n in range(8,12)],\"min_samples_leaf\":[2,5]}\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_grilla = GridSearchCV(rf_model,hyperparam,cv=10,scoring=score_metric,n_jobs=-1)\n",
    "rf_grilla.fit(feat_train,targ_train)\n",
    "rf_model = rf_grilla.best_estimator_\n",
    "print(rf_grilla.best_params_)\n",
    "print(\"Grilla Best Score: {:.3f}\".format(rf_grilla.best_score_))\n",
    "rf_scoring = cross_val_score(rf_model, feat_train, targ_train,cv=10, scoring=score_metric)\n",
    "print(\"Cross Validation Score: {:.3f} +/- {:.3f}\".format(rf_scoring.mean(),rf_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring en Test: 0.632\n"
     ]
    }
   ],
   "source": [
    "#print(\"Scoring en Test: {:.3f}\".format(recall_score(targ_test,rf_model.predict((feat_test-t_mean)/t_var))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADABOOST CLASIFFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'n_estimators': 500}\n",
      "Grilla Best Score: 0.837\n",
      "Cross Validation Score: 0.786 +/- 0.179\n"
     ]
    }
   ],
   "source": [
    "hyperparam = {\"n_estimators\":[100,500,1000,5000],\"learning_rate\":[0.1,0.3,0.5,1]}\n",
    "ada_model = AdaBoostClassifier(DecisionTreeClassifier(), algorithm=\"SAMME.R\")\n",
    "ada_grilla = GridSearchCV(ada_model,hyperparam,cv=10,scoring=score_metric,n_jobs=-1)\n",
    "ada_grilla.fit(feat_train,targ_train)\n",
    "ada_model = rf_grilla.best_estimator_\n",
    "print(ada_grilla.best_params_)\n",
    "print(\"Grilla Best Score: {:.3f}\".format(ada_grilla.best_score_))\n",
    "ada_scoring = cross_val_score(ada_model, feat_train, targ_train,cv=10, scoring=score_metric)\n",
    "print(\"Cross Validation Score: {:.3f} +/- {:.3f}\".format(ada_scoring.mean(),ada_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring en Test: 0.632\n"
     ]
    }
   ],
   "source": [
    "print(\"Scoring en Test: {:.3f}\".format(recall_score(targ_test,ada_model.predict((feat_test-t_mean)/t_var))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_train_2, feat_val, targ_train_2, targ_val = train_test_split(feat_train,targ_train)\n",
    "# NECESARIO CREAR DATOS DE VALIDACION PARA USAR XGBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: 0.763 +/- 0.151\n"
     ]
    }
   ],
   "source": [
    "xgbc_model = XGBClassifier(use_label_encoder=False, n_estimators=2000, learning_rate=0.2, objective='binary:hinge',max_depth=7)\n",
    "xgbc_model.fit(feat_train_2,targ_train_2,eval_set=[(feat_train_2, targ_train_2), (feat_val, targ_val)],eval_metric='logloss',early_stopping_rounds=30,verbose=False)\n",
    "xgbc_scoring = cross_val_score(xgbc_model, feat_train, targ_train,cv=10, scoring=score_metric)\n",
    "print(\"Cross Validation Score: {:.3f} +/- {:.3f}\".format(xgbc_scoring.mean(),xgbc_scoring.std()))\n",
    "# VER TEMA DE METRICA ACA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc_model.predict(scaler.transform(feat_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d9579fd63862c719ce91d1dd1fb1c44b2ef43bdaa2f86d843d9fd8562746d35b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
